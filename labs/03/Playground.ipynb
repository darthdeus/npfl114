{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import timeit\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from uppercase import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 3\n",
    "alphabet_size = 100\n",
    "\n",
    "train = Dataset(\"data/uppercase_data_train.txt\", window, alphabet=alphabet_size)\n",
    "dev = Dataset(\"data/uppercase_data_dev.txt\", window, alphabet=train.alphabet)\n",
    "test = Dataset(\"data/uppercase_data_test.txt\", window, alphabet=train.alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "for i in range(args.epochs):\n",
    "    while not train.epoch_finished():\n",
    "        windows, labels = train.next_batch(args.batch_size)\n",
    "        network.train(windows, labels)\n",
    "\n",
    "    dev_windows, dev_labels = dev.all_data()\n",
    "    network.evaluate(\"dev\", dev_windows, dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(7, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 2),\n",
    "    nn.Softmax(1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6956028938293457\n",
      "0.6937083005905151\n",
      "0.6935012340545654\n",
      "0.6933033466339111\n",
      "0.6932116746902466\n",
      "0.6932079195976257\n",
      "0.6931992173194885\n",
      "0.6931772828102112\n",
      "0.6931777000427246\n",
      "0.6931762099266052\n",
      "0.6931754350662231\n",
      "0.6931622624397278\n",
      "0.69316166639328\n",
      "0.6931880712509155\n",
      "0.69315505027771\n",
      "0.693149745464325\n",
      "0.6931516528129578\n",
      "0.6931527853012085\n",
      "0.6931503415107727\n",
      "0.6931511759757996\n",
      "0.6931493282318115\n",
      "0.6931515336036682\n",
      "0.6931524276733398\n",
      "0.6931509971618652\n",
      "0.6931476593017578\n",
      "0.6931478977203369\n",
      "0.6931474208831787\n",
      "0.693147599697113\n",
      "0.6931479573249817\n",
      "0.6931496858596802\n",
      "0.6931483149528503\n",
      "0.6931504607200623\n",
      "0.6931480169296265\n",
      "0.6931473612785339\n",
      "0.693148672580719\n",
      "0.6931506395339966\n",
      "0.6931474804878235\n",
      "0.693148136138916\n",
      "0.6931486129760742\n",
      "0.6931472420692444\n",
      "0.6931478977203369\n",
      "0.6931478977203369\n",
      "0.6931474208831787\n",
      "0.6931489109992981\n",
      "0.6931472420692444\n",
      "0.6931532025337219\n",
      "0.6931473612785339\n",
      "0.6931472420692444\n",
      "0.6931475400924683\n",
      "0.693147599697113\n",
      "0.6931473016738892\n",
      "0.6931473612785339\n",
      "0.6931582689285278\n",
      "0.6931473612785339\n",
      "0.6931473612785339\n",
      "0.6931476593017578\n",
      "0.6931472420692444\n",
      "0.693147599697113\n",
      "0.6931471824645996\n",
      "0.6931473016738892\n",
      "0.6931474208831787\n",
      "0.6931472420692444\n",
      "0.6931473016738892\n",
      "0.6931490898132324\n",
      "0.693147599697113\n",
      "0.6931472420692444\n",
      "0.6931473612785339\n",
      "0.6931475400924683\n",
      "0.6931474804878235\n",
      "0.6931473612785339\n",
      "0.6931471824645996\n",
      "0.6931478381156921\n",
      "0.6931473016738892\n",
      "0.6931474804878235\n",
      "0.693148672580719\n",
      "0.6931471824645996\n",
      "0.6931473016738892\n",
      "0.6931472420692444\n",
      "0.6931471824645996\n",
      "0.6931473612785339\n",
      "0.6931474208831787\n",
      "0.6931473016738892\n",
      "0.6931471824645996\n",
      "0.6931481957435608\n",
      "0.6931499242782593\n",
      "0.6931476593017578\n",
      "0.6931471824645996\n",
      "0.6931477189064026\n",
      "0.6931471824645996\n",
      "0.6931474208831787\n",
      "0.6931473016738892\n",
      "0.6931471824645996\n",
      "0.6931472420692444\n",
      "0.6931474804878235\n",
      "0.6931509971618652\n",
      "0.6931473612785339\n",
      "0.6931472420692444\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931472420692444\n",
      "0.6931473016738892\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931486129760742\n",
      "0.6931472420692444\n",
      "0.6931472420692444\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931472420692444\n",
      "0.6931472420692444\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931472420692444\n",
      "0.6931472420692444\n",
      "0.6931471824645996\n",
      "0.6931474804878235\n",
      "0.6931521892547607\n",
      "0.6931472420692444\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931478381156921\n",
      "0.6931473016738892\n",
      "0.6931472420692444\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931473612785339\n",
      "0.6931471824645996\n",
      "0.6931479573249817\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931480169296265\n",
      "0.6931472420692444\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931473612785339\n",
      "0.6931474804878235\n",
      "0.6931472420692444\n",
      "0.6931472420692444\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931472420692444\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931473016738892\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931474804878235\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931473016738892\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931472420692444\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931473612785339\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n",
      "0.6931471824645996\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "the given numpy array has zero-sized dimensions. Zero-sized dimensions are not supported in PyTorch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-64fdd0993e35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: the given numpy array has zero-sized dimensions. Zero-sized dimensions are not supported in PyTorch"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for _ in range(2):\n",
    "    while not train.epoch_finished():\n",
    "        i += 1\n",
    "        windows, labels = train.next_batch(50)\n",
    "\n",
    "        X, y = train.next_batch(50)\n",
    "        X = Variable(torch.from_numpy(X).float())\n",
    "        y = Variable(torch.from_numpy(y.astype(np.float32))).view(-1, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(X)\n",
    "        loss = -(y * preds.log() + (1 - y) * (1 - preds).log()).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()    # Does the update\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
